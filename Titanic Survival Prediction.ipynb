{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Split the data into features and labels\n",
    "X_train = train_df.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y_train = train_df['Survived']\n",
    "X_test = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Preprocess the data  EDA\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].median())\n",
    "X_train['Embarked'] = X_train['Embarked'].fillna(X_train['Embarked'].mode()[0])\n",
    "X_train['Sex'] = X_train['Sex'].map({'female': 0, 'male': 1})\n",
    "X_train['Embarked'] = X_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "X_test['Age'] = X_test['Age'].fillna(X_test['Age'].median())\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].median())\n",
    "X_test['Embarked'] = X_test['Embarked'].fillna(X_test['Embarked'].mode()[0])\n",
    "X_test['Sex'] = X_test['Sex'].map({'female': 0, 'male': 1})\n",
    "X_test['Embarked'] = X_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the KNN model using cross-validation\n",
    "k_range = range(1, 21)\n",
    "cv_scores = []\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Select the best k value based on the highest cross-validation score\n",
    "best_k = np.argmax(cv_scores) + 1\n",
    "print('Best k:', best_k)\n",
    "\n",
    "# Train the KNN model on the training set using the best k value\n",
    "model = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_valid = model.predict(X_valid_split)\n",
    "valid_acc = accuracy_score(y_valid_split, y_pred_valid)\n",
    "valid_precision = precision_score(y_valid_split, y_pred_valid)\n",
    "valid_recall = recall_score(y_valid_split, y_pred_valid)\n",
    "valid_f1 = f1_score(y_valid_split, y_pred_valid)\n",
    "# print('Validation accuracy:', valid_acc)\n",
    "# print('Validation precision:', valid_precision)\n",
    "# print('Validation recall:', valid_recall)\n",
    "# print('Validation F1-score:', valid_f1)\n",
    "\n",
    "# Apply the trained model to the test set for predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "test_df['Survived'] = y_pred\n",
    "\n",
    "\n",
    "#print(test_df['Survived'])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the confusion matrix\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model using cross-validation\n",
    "model = GaussianNB()\n",
    "scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Train the Naive Bayes model on the training set\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_valid = model.predict(X_valid_split)\n",
    "valid_acc = accuracy_score(y_valid_split, y_pred_valid)\n",
    "print('Validation accuracy:', valid_acc)\n",
    "\n",
    "# Calculate the confusion matrix for the validation set predictions\n",
    "conf_matrix_valid = confusion_matrix(y_valid_split, y_pred_valid)\n",
    "print('Confusion Matrix (Validation Set):\\n', conf_matrix_valid)\n",
    "\n",
    "# Apply the trained model to the test set for predictions\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "test_df['Survived'] = y_pred_test\n",
    "\n",
    "# Calculate the confusion matrix for the test set predictions\n",
    "# Replace y_test with the actual labels for the test set\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix (Test Set):\\n', conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an MLPClassifier model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = mlp.predict(X_train_scaled)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "\n",
    "# Apply the trained model to the testing set for predictions\n",
    "y_test_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Print the predicted values\n",
    "print(\"Predicted values for test data:\")\n",
    "print(y_test_pred)\n",
    "\n",
    "# Calculate the confusion matrix for the training set predictions\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "print('Confusion Matrix (Training Set):\\n', conf_matrix_train)\n",
    "\n",
    "# Calculate the confusion matrix for the test set predictions\n",
    "# Replace y_test with the actual labels for the test set\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "print('Confusion Matrix (Test Set):\\n', conf_matrix_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis\n",
    "\n",
    "\n",
    "Compare  the  performance  of the  three  algorithms  (KNN,  Naive  Bayes, and ANN) based on the evaluation metrics  obtained: \n",
    "\n",
    "To compare the performance of the three algorithms (KNN, Naive Bayes, and ANN), we can compare their evaluation metrics. Here's a summary of the evaluation metrics for each algorithm, based on the code you provided:\n",
    "\n",
    "KNN:\n",
    "\n",
    "Validation accuracy: 0.804\n",
    "Confusion matrix (validation set):\n",
    "\n",
    "[[239   8]\n",
    " [ 38 133]]\n",
    "\n",
    "\n",
    "\n",
    "Naive Bayes:\n",
    "\n",
    "Validation accuracy: 0.789\n",
    "Confusion matrix (validation set):\n",
    " [[84 21]\n",
    " [20 54]]\n",
    "\n",
    "ANN:\n",
    "Training accuracy: 0.843\n",
    "Confusion matrix (training set):\n",
    " [[529  20]\n",
    " [ 73 269]]\n",
    "\n",
    "\n",
    "Based on these metrics, we can see that the KNN model has the highest validation accuracy, followed  by the Naive Bayes model. However, the ANN model has a higher training accuracy, indicating that it may have more potential to improve with further  optimization.\n",
    "\n",
    "\n",
    "In terms of strengths and weaknesses, the KNN algorithm is simple and easy to understand, and can work well with non-linear and complex data. However, it may not perform well with high-dimensional data and can be sensitive to outliers. The Naive Bayes algorithm is also simple and fast, and can handle high-dimensional data well. However, it assumes that features are independent and may not work well with correlated features. The ANN algorithm is highly flexible and can learn complex patterns in the data, but it requires more data and computational resources to train, and can be prone to overfitting.\n",
    "\n",
    "\n",
    "Overall, based on the evaluation metrics and the strengths and weaknesses of each algorithm, it seems that the KNN and Naive Bayes algorithms perform similarly well on the Titanic dataset, while the ANN algorithm may have more potential for improvement with further optimization.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
